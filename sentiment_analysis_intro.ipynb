{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c95b88b3-f7c1-48cc-ac9e-619ca5f5f4a8",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #492c68;\">NLP: Sentiment Analysis</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca0feb6-93b0-4616-a894-50ecfc8f6371",
   "metadata": {},
   "source": [
    "We are going dive into a basic introduction for <mark>Sentiment Analisis</mark> through <mark>Natural Language Processing</mark>. \n",
    "\n",
    "- As always, we read our dataset. Let's see what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1312fb19-bb7e-4b3a-9747-7a3af8f48cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Basic Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## EDA Libraries\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import plotly as px\n",
    "\n",
    "## Settings configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75957d1-c6be-4440-8b78-0cfbfa9ef1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1870d1e0-17e0-4845-829f-527ffa145486",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best setting for columns names\n",
    "\n",
    "df.columns = df.columns.str.lower().str.replace(\" \",\"_\").str.replace(\".\",\"_\").str.replace(\":\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc4fb7-df38-4b82-bd89-c2858a996699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b98afbf-e4df-4f9c-9f1f-2836f374bb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b6bb8-0640-4d37-abe9-e7df9ebbe479",
   "metadata": {},
   "source": [
    "From df we have interest about <mark>\"score\"</mark>, <mark>\"summary\"</mark> and <mark>\"text\"</mark>\n",
    "\n",
    "- \"text\": is the most important variable in our project. These texts will be break down into tokens and processed to figure out their sentiment.\n",
    "- \"score\" and \"sumary\" are useful to compare our new results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f301ef-09b5-49cf-873d-91d20b405da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[[\"text\", \"score\", \"summary\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e943cb1-a17b-4841-8fc7-abe3856a7ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d1856-f7db-48f6-8a8b-415f037e7cc8",
   "metadata": {},
   "source": [
    "- Before we go further, let's plot \"score\" to see its distribution and have an idea of the data we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35ea59-c61d-49c1-bf27-f47396fd546e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(data= df[\"score\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f2d8ac-2bb2-495d-9fde-94507a6086c1",
   "metadata": {},
   "source": [
    "- Lenght its too big. It would be better if we use a fraction of it to make it easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ba73e-8aba-4153-a61f-618082a230fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce6cfe3-8df5-4713-b0dc-83592d33c6b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2 style=\"color: #327a81;\">NLP Preprocessing: NLTK Basics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d20420-ee61-40a1-81d3-355c56d76e4b",
   "metadata": {},
   "source": [
    "<mark>NLTK</mark> means <mark>Natural Language Toolkit</mark>. It's a basic tool for <mark>NLP beginners</mark> and <mark>quick model processing</mark>. It's not too fancy but can be used to understand basics.\n",
    "\n",
    "- Let's see how NLTK works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee623e9-6b03-4420-9304-383c48685bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Installing the specific librarie\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt') #tokenizer package\n",
    "nltk.download('averaged_perceptron_tagger') #For label tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec68b5-5517-4797-b29c-8f46819882b7",
   "metadata": {},
   "source": [
    "- For this demo. We take a random index as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e74adc-00b4-424f-8699-ff4c965ef101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example = df[\"text\"][65]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26c5db-d2cf-4a2c-98ac-61a269fcae47",
   "metadata": {},
   "source": [
    "- NTLK can tokenize any text. This is crucial for the ML preprocessing.\n",
    "- Tokenizer may seem similar to splitting strings, but it's more complex than that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fddeffb-5aac-4cca-90f3-079123189135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(example) # word_tokenize breaks the string into tokens that the machine understands\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a168214-d096-4e13-8d08-599782eb014e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk.pos_tag(tokens) # pos_tag shows the grammar labels of the tokens. Look for pos_tag list in google to know more about abreviations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dccaee-3cfa-4bb0-aaf8-73b11c29f9b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2 style=\"color: #327a81;\">Sentiment Analysis: VADER and RoBERTa</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d70b8-ad54-45a8-b217-6903b9f31702",
   "metadata": {},
   "source": [
    "There are lot of ways to do Sentiment Analaysis. For this introduction we will see two different types.\n",
    "\n",
    "- <mark>VADER</mark> to see the <mark>positive/negative valance</mark> of the sentences (basic)\n",
    "- <mark>RoBERTa</mark> to do a <mark>mood analysis</mark> (complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d83b83-13f0-4df4-ada1-2c07e8c98fb5",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #60b671;\">VADER</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b770aa-801a-41c3-829c-ae5e91309d04",
   "metadata": {},
   "source": [
    "VADER stands for <mark>Valance Aware Dictionary and Sentiment Reasoner</mark>. This NLTK tool is used to figure out if a piece of text is expressing positive, negative or neutral emotions.\n",
    "\n",
    "- This method uses a <mark>\"bag of words\"</mark> approach. This means that the analysis uses the weight of the words (understands the positive charge without context)\n",
    "- Can be <mark>more accessible for beginners</mark> than RoBERTa. It's recommended for fast prototypes... but has lots of limitations (self-awareness, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c12e1-73f8-457d-94d5-73f32ce8c6fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Installing NLTK specific function\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf541ed6-4bb7-4acc-a08a-8c872fecf6cb",
   "metadata": {},
   "source": [
    "- Once we have defined our sia, we can test it with our previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ecbdd-5a37-47f8-9999-6ac92fdeaa8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b2369-7f68-4de4-a00f-4cc9075addda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sia.polarity_scores(example) # polarity_scores give us pos/neg/neu values from -1 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b56ca8-741d-4a9b-aa15-0ca2bde6d608",
   "metadata": {},
   "source": [
    "- Scores in the example are not bad. Tends to be neutral/positive, ditching the negative value\n",
    "- So this matches with the real score and its summary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a76227-8d77-4a29-bffc-f89ad0cee40d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[65] # Check the example's polarity with real ratings, to see if it fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08601cf9-606d-49f1-96f1-d96386140345",
   "metadata": {},
   "source": [
    "Now that we know how polarity scores works, let's apply this function to all texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c7186-1edc-45d6-9e82-89c388adb988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Polarity Scores through Iterrows on the \"text\" column\n",
    "\n",
    "pol_scores = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    text = row[\"text\"]\n",
    "    scores = sia.polarity_scores(text)\n",
    "    pol_scores[i] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de47377-4bbd-4504-afde-35a3829009ce",
   "metadata": {},
   "source": [
    "- We can compare the polarity scores with \"score\" and \"summary\" to check if they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385bde29-d673-4f04-990b-09f492dd1289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pol_scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2bc718-a2ad-43bd-a688-1f5805011d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's unify both dataframes (original + polarity scores) to see if our sentiments match\n",
    "\n",
    "vaders = pd.DataFrame(pol_scores).T\n",
    "\n",
    "vaders = pd.concat([df, vaders], axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b464adbe-06d4-447d-9da5-ea2654e97578",
   "metadata": {},
   "source": [
    "- Let's check how scores 1 went after the polarity. It would tend to negative side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6776ef-249a-43c0-8ee2-c86b55ad16e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vaders.groupby(\"score\").get_group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401a4e7-ded2-4391-b4cf-214436c19a48",
   "metadata": {
    "tags": []
   },
   "source": [
    "- We can compare ratings with polarity scores through a quick plot.\n",
    "- We can use \"compound\" to see this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcce5fc-46b7-4067-966a-da20a6447af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=vaders, x=\"score\", y=\"compound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7deda-3e50-4029-89ac-7bb3225d1ad2",
   "metadata": {},
   "source": [
    "<h3 style=\"color: #60b671;\">RoBERTa</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f9afc2-bf89-46fb-9e8c-57726828337e",
   "metadata": {},
   "source": [
    "RoBERTa stands for <mark>Robustly Optimized BERT Approach</mark>. Is a variant of the BERT (Bidirectional Encoder Representations from Transformers) model. \n",
    "\n",
    "- Transformers is a step fordward in the NLP field. This deep learning model focus on <mark>attention mechanism</mark>, which allows it to recognise different parts of an input sequence.\n",
    "- The attention mechanism is key to a text's <mark>self-awareness</mark>. Complex syntactic structures or different intentions, like sarcasm, can be processed by Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46730c13-87ca-4431-bab6-65bce21147a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Installing Transformers specific functions\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2066042-2839-4c77-a359-38a3b9ee4055",
   "metadata": {},
   "source": [
    "- We will use a RoBERTa petrained model named Emotion English DistilRoBERTa-base. It's a refined embedding that can <mark>break text into emotion moods</mark>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3a771-f49b-45a7-a05f-f2b40f16c5ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "\n",
    "MODEL = f\"j-hartmann/emotion-english-distilroberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301ab2f-013d-4331-b073-219be57b0e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's see through a pipeline example how it works\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", MODEL, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7bf865-5a2f-4b7c-b759-eca42c818aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try any example message\n",
    "\n",
    "classifier(\"It was really nice to meet you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525df7bc-c8e5-471b-a4e1-696bfa9c15fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "- After seeing how transformers works, let's apply the model in our texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c1c37-bd6b-491f-9816-5fdfd69ad5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save functions that will help us\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007f5c2-fafd-42f8-835e-33c938a1b811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the function for obtaining the scores\n",
    "\n",
    "def mooder(text):\n",
    "    max_lenght = 512\n",
    "    encoded_text = tokenizer(text, return_tensors=\"pt\", max_length=max_lenght, truncation=True, padding=\"longest\")\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    moods = {\n",
    "    \"anger\": scores[0],\n",
    "    \"disgust\" : scores[1],\n",
    "    \"fear\": scores[2],\n",
    "    \"joy\": scores[3],\n",
    "    \"neutral\": scores[4], \n",
    "    \"sadness\": scores[5],\n",
    "    \"surprise\": scores[6]\n",
    "    }\n",
    "    \n",
    "    return moods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe5326-d7c6-443b-a67d-6389f0744f40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roberta =  df[\"text\"].apply(mooder) # We apply the function defined before to have all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40082692-13cd-4faf-9dda-521fa5ae2de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roberta = pd.DataFrame(roberta)\n",
    "roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58940469-570c-44a3-8c4c-1d69391af9be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roberta_scores = pd.json_normalize(roberta[\"text\"]) # Normalize the df to put all elements in dictionary as columns and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0f7ce-2eeb-4368-8666-00f7b023ba1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moods = pd.concat([df, roberta_scores], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40672e6-12d0-49ad-a40e-e31dccb54fff",
   "metadata": {},
   "source": [
    "- Let's take a sneak peak to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b75f91-e5be-45f8-996f-65e8f7aed69d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moods.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ea136-ada7-4ef1-aa13-f02fa7b48571",
   "metadata": {},
   "source": [
    "- We could check by any mood the scores to see if matches our expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1925c23-ad1c-4f00-a9a7-7ba9b636450b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moods.sort_values(by=\"disgust\", ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160713f2-0bd7-465c-89d5-9bb67bc7de37",
   "metadata": {
    "tags": []
   },
   "source": [
    "- As we did it before with VADERS, we can plot and compare ratings with a specific type of score to see if it fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b843374c-8f46-465b-b723-39199e493362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=moods, x=\"score\", y=\"disgust\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
